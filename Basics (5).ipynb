{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a spam filter with Naive Bayes #\n",
    "\n",
    "Using a dataset by Tiago A. Almeida and Jose Maria Gomez Hidalgo - downloaded from The [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection), our goal is to build a spam filter by teaching the computer how to classify messages like a human would using **Multinomial Naive Bayes**. Using that, the computer will then classify messsages as spam and non-spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "collection = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label','SMS'])\n",
    "collection.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating total spam labels and ham (non-spam) labels: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam and Non-spam percentages respectively: 87.0 13.0\n"
     ]
    }
   ],
   "source": [
    "spam = collection[collection['Label'] == 'spam']['Label'].count()/collection.shape[0]\n",
    "ham = collection[collection['Label'] == 'ham']['Label'].count()/collection.shape[0]\n",
    "print('Spam and Non-spam percentages respectively:',round(ham,2)*100,round(spam,2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting datasets into test and training ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "1078   ham                       Yep, by the pretty sculpture\n",
       "4028   ham      Yes, princess. Are you going to make me moan?\n",
       "958    ham                         Welp apparently he retired\n",
       "4642   ham                                            Havent.\n",
       "4674   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random = collection.sample(frac=1, random_state=1)\n",
    "random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "training_index = round(int(random['Label'].count() * 0.8))\n",
    "training = random[ : training_index].reset_index(drop=True)\n",
    "test = random[training_index :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of spam and non-spam in training dataset:13%,87%\n"
     ]
    }
   ],
   "source": [
    "training_spam = training[training['Label']=='spam']['Label'].count()/training.shape[0]\n",
    "training_n_spam = training[training['Label']=='ham']['Label'].count()/training.shape[0]\n",
    "print('Percentage of spam and non-spam in training dataset:{0}%,{1}%'.format(round(training_spam * 100), round(training_n_spam *100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of spam and non-spam in test dataset:13%,87%\n"
     ]
    }
   ],
   "source": [
    "test_spam = test[test['Label']=='spam']['Label'].count()/test.shape[0]\n",
    "test_n_spam = test[test['Label']=='ham']['Label'].count()/test.shape[0]\n",
    "print('Percentage of spam and non-spam in test dataset:{0}%,{1}%'.format(round(test_spam * 100), round(test_n_spam *100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice that the percentages of spam and non spam have not changed even after splitting the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert all upper case letter to slower case so the words can be considered the same, and remove all symbols.\n",
    "This will allow is to transform the dataset's sms columns into **multiple columns of words and their counts**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "training['SMS'] = training['SMS'].str.lower()\n",
    "training['SMS'] = training['SMS'].str.replace(r'\\W',' ')\n",
    "test['SMS'] = test['SMS'].str.lower()\n",
    "test['SMS'] = test['SMS'].str.replace(r'\\W', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting strings in the SMS column\n",
    "\n",
    "training['SMS'] = training['SMS'].str.split()\n",
    "vocabulary = []\n",
    "\n",
    "for row in training['SMS']:\n",
    "    for word in row:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "vocabulary = set(vocabulary)\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the screen above we created a vocabulary list containing a single copy of all  space separated strings from SMS column of the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "word_count = pd.DataFrame(word_counts_per_sms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urgent</th>\n",
       "      <th>ileave</th>\n",
       "      <th>tendencies</th>\n",
       "      <th>aphex</th>\n",
       "      <th>honeymoon</th>\n",
       "      <th>oops</th>\n",
       "      <th>studies</th>\n",
       "      <th>expires</th>\n",
       "      <th>happy</th>\n",
       "      <th>speeding</th>\n",
       "      <th>...</th>\n",
       "      <th>pints</th>\n",
       "      <th>07046744435</th>\n",
       "      <th>yetty</th>\n",
       "      <th>isnt</th>\n",
       "      <th>news</th>\n",
       "      <th>900</th>\n",
       "      <th>mesages</th>\n",
       "      <th>4eva</th>\n",
       "      <th>hesitant</th>\n",
       "      <th>69669</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   urgent  ileave  tendencies  aphex  honeymoon  oops  studies  expires  \\\n",
       "0       0       0           0      0          0     0        0        0   \n",
       "1       0       0           0      0          0     0        0        0   \n",
       "2       0       0           0      0          0     0        0        0   \n",
       "3       0       0           0      0          0     0        0        0   \n",
       "4       0       0           0      0          0     0        0        0   \n",
       "\n",
       "   happy  speeding  ...  pints  07046744435  yetty  isnt  news  900  mesages  \\\n",
       "0      0         0  ...      0            0      0     0     0    0        0   \n",
       "1      0         0  ...      0            0      0     0     0    0        0   \n",
       "2      0         0  ...      0            0      0     0     0    0        0   \n",
       "3      0         0  ...      0            0      0     0     0    0        0   \n",
       "4      0         0  ...      0            0      0     0     0    0        0   \n",
       "\n",
       "   4eva  hesitant  69669  \n",
       "0     0         0      0  \n",
       "1     0         0      0  \n",
       "2     0         0      0  \n",
       "3     0         0      0  \n",
       "4     0         0      0  \n",
       "\n",
       "[5 rows x 7782 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "training_count = pd.concat([training,word_count], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the spam filter ##\n",
    "We're going to use the naive bayes equation:\n",
    "\n",
    "p(spam|w1, w2, w3, ... wn) ~= p(spam) x  p(w1|spam) x  p(w2|spam) x ... x p(wn|spam)\n",
    "\n",
    "to train the program to recognize spam messages by creating a filter. We'rs going to do this on the training set.\n",
    "\n",
    "### Calculating Constants ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "spam_set = training_count[training_count['Label']=='spam']\n",
    "ham_set = training_count[training_count['Label']=='ham']\n",
    "p_spam = spam_set['Label'].count()/training_count.shape[0]\n",
    "p_spam = round(p_spam,2)\n",
    "p_ham = ham_set['Label'].count()/training_count.shape[0]\n",
    "p_ham = round(p_ham,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "n_spam_row = spam_set.sum(axis=1)\n",
    "n_spam = n_spam_row.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "n_ham_row = ham_set.sum(axis=1)\n",
    "n_ham = n_ham_row.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#no of words\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "#Laplace smoothing constant\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_spam = {}\n",
    "d_ham = {}\n",
    "\n",
    "for col in word_count.columns:\n",
    "    d_spam[col] = 0\n",
    "    d_ham[col] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_set_messages = spam_set['SMS']\n",
    "ham_set_messages = ham_set['SMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for skey, hkey in zip(d_spam, d_ham):\n",
    "    d_spam[skey] = (spam_set[skey].sum() + alpha )/(n_spam + (alpha*n_vocabulary))\n",
    "    d_ham[hkey] = (ham_set[hkey].sum() + alpha)/(n_ham + (alpha * n_vocabulary))\n",
    "   \n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    global p_spam_all_words \n",
    "    global p_ham_all_words \n",
    "    p_spam_all_words = 1\n",
    "    p_ham_all_words = 1\n",
    "    for word in message:\n",
    "        if word in d_spam.keys():\n",
    "            p_spam_all_words = p_spam_all_words * d_spam[word]\n",
    "        if word in d_ham.keys():\n",
    "            p_ham_all_words = p_ham_all_words * d_ham[word]\n",
    "    p_spam_given_message = p_spam * p_spam_all_words\n",
    "    p_ham_given_message = p_ham * p_ham_all_words\n",
    "   \n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing our filter ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.head(5))\n",
    "test[0:5]['SMS'].apply(classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results ##\n",
    "The results are looking good and we have successfully built a spam filter with a great accuracy rate!."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
